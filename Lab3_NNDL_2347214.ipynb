{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WnnI0Nqb-q8",
        "outputId": "a833289d-0779-4711-ae16-adf39a5697d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 1. Normalize pixel values to range between 0 and 1\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# 2. Convert class labels into one-hot encoded format\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 3. Split dataset (already done; 50,000 for training, 10,000 for testing)\n",
        "# CIFAR-10 is already split into 50,000 training and 10,000 test images.\n",
        "\n",
        "# 4. Data augmentation (Optional)\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,    # Random rotations\n",
        "    width_shift_range=0.1,  # Random horizontal shifts\n",
        "    height_shift_range=0.1,  # Random vertical shifts\n",
        "    horizontal_flip=True    # Random horizontal flips\n",
        ")\n",
        "\n",
        "# Fit the generator on the training data\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# To use the augmented data for training:\n",
        "# model.fit(datagen.flow(x_train, y_train, batch_size=64), epochs=..., validation_data=(x_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the model architecture\n",
        "model = models.Sequential()\n",
        "\n",
        "# Input layer: The input shape matches the 32x32x3 dimensions of CIFAR-10 images\n",
        "model.add(layers.InputLayer(input_shape=(32, 32, 3)))\n",
        "\n",
        "# 1st Convolutional Layer: 32 filters, 3x3 kernel, ReLU activation\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # Max pooling layer\n",
        "\n",
        "# 2nd Convolutional Layer: 64 filters, 3x3 kernel, ReLU activation\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # Max pooling layer\n",
        "\n",
        "# 3rd Convolutional Layer: 128 filters, 3x3 kernel, ReLU activation\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))  # Max pooling layer\n",
        "\n",
        "# Flatten the output from convolutional layers\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "# Fully Connected Layer (Dense layer): 512 neurons, ReLU activation\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "\n",
        "# Output Layer: 10 output neurons for 10 classes with softmax activation\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "n5uTRYAdd37K",
        "outputId": "ab616899-bdaf-4f1b-bc43-1a9939f7fa51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │       \u001b[38;5;34m1,049,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m5,130\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,147,466\u001b[0m (4.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147,466</span> (4.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,147,466\u001b[0m (4.38 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,147,466</span> (4.38 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question\n",
        "Justify your choice of network architecture, including the number of  layers, types of layers, and the number of neurons/filters in each layer.\n",
        "\n",
        "The input layer accepts images with shape (32, 32, 3) to match the CIFAR-10 image dimensions (32x32 pixels with 3 color channels).\n",
        "\n",
        "Number of Filters: Starting with 32 filters and increasing to 64 and then 128 allows the network to progressively learn more complex features, starting with edges and simple patterns in the first layers and moving to more abstract representations (like textures and object parts) in the deeper layers.\n",
        "Kernel Size: The 3x3 kernel size is standard in image recognition tasks, providing a balance between capturing fine details and maintaining computational efficiency.\n",
        "Activation (ReLU): The ReLU activation function helps introduce non-linearity, which allows the network to model complex patterns while being computationally efficient.\n",
        "MaxPooling: The pooling layers reduce the spatial dimensions of the image (by 2x2), thus reducing the number of parameters and helping to prevent overfitting, while retaining important features.\n",
        "\n",
        "512 Neurons: A fully connected layer with 512 neurons provides a large capacity for learning complex representations of the image data. This size is a trade-off between model complexity and performance.\n"
      ],
      "metadata": {
        "id": "TmOKPQuOeHnY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activation Function\n",
        "\n",
        "## ReLU (Rectified Linear Unit):\n",
        "Formula:\n",
        "f(x)=max(0,x)\n",
        "Why ReLU?:\n",
        "\n",
        "Simplicity: The ReLU function is computationally simple and efficient as it only outputs zero or the input value.\n",
        "Non-Linearity: It introduces non-linearity into the model, which is essential for capturing complex patterns and representations in the data.\n",
        "Avoiding Vanishing Gradients: Unlike the sigmoid and tanh functions, which can lead to the \"vanishing gradient\" problem (where gradients become very small in backpropagation), ReLU helps avoid this by keeping gradients large when the input is positive. This leads to faster training and better convergence.\n",
        "Sparse Activation: ReLU introduces sparsity into the network (many neurons output 0 for negative inputs), making the model more computationally efficient and helping reduce the likelihood of overfitting.\n",
        "\n",
        "### Role during Backpropagation\n",
        "During backpropagation, ReLU allows gradients to pass through for positive inputs (where the derivative is 1) but stops the gradient flow for negative inputs (derivative is 0). This selective gradient propagation helps the model converge faster since it avoids the problem of small gradients for large inputs.\n",
        "\n",
        "\n",
        "## Tanh (Hyperbolic Tangent):\n",
        "Why Tanh?:\n",
        "\n",
        "Centered Output: The tanh function outputs values in the range [-1, 1], making it \"centered\" around zero. This property helps in balancing the data, ensuring that the outputs of the neurons have both positive and negative values. This can lead to faster convergence during backpropagation.\n",
        "Non-Linearity: Like ReLU, tanh is also a non-linear function, which allows the network to learn more complex patterns.\n",
        "Better for Symmetry: Since tanh outputs both negative and positive values, it can help in reducing biases in networks where centered values are needed.\n",
        "\n",
        "### Role in Backpropagation:\n",
        "This derivative is small for extreme values of x, meaning that tanh can suffer from the vanishing gradient problem, but it works well in practice for many applications, especially in deeper layers. The gradient flows effectively for moderate input values (around 0), which helps with effective learning."
      ],
      "metadata": {
        "id": "KHcB7oGae7_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model with Adam and Categorical Cross Entropy\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Training the model\n",
        "history = model.fit(x_train, y_train, epochs=50, batch_size=64, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTw8ZXmAgVlg",
        "outputId": "f77bf9ec-3722-4c0f-c059-371822a20f7d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 11ms/step - accuracy: 0.9593 - loss: 0.1162 - val_accuracy: 0.7513 - val_loss: 1.2401\n",
            "Epoch 2/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9702 - loss: 0.0870 - val_accuracy: 0.7544 - val_loss: 1.2726\n",
            "Epoch 3/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0798 - val_accuracy: 0.7524 - val_loss: 1.3138\n",
            "Epoch 4/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.0681 - val_accuracy: 0.7557 - val_loss: 1.3385\n",
            "Epoch 5/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0583 - val_accuracy: 0.7450 - val_loss: 1.4436\n",
            "Epoch 6/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0778 - val_accuracy: 0.7521 - val_loss: 1.5030\n",
            "Epoch 7/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0627 - val_accuracy: 0.7408 - val_loss: 1.5252\n",
            "Epoch 8/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0541 - val_accuracy: 0.7456 - val_loss: 1.6497\n",
            "Epoch 9/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9795 - loss: 0.0571 - val_accuracy: 0.7443 - val_loss: 1.7223\n",
            "Epoch 10/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9771 - loss: 0.0644 - val_accuracy: 0.7527 - val_loss: 1.7142\n",
            "Epoch 11/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0421 - val_accuracy: 0.7548 - val_loss: 1.7406\n",
            "Epoch 12/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0524 - val_accuracy: 0.7422 - val_loss: 1.7729\n",
            "Epoch 13/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0547 - val_accuracy: 0.7503 - val_loss: 1.8564\n",
            "Epoch 14/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0470 - val_accuracy: 0.7477 - val_loss: 1.9181\n",
            "Epoch 15/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0442 - val_accuracy: 0.7427 - val_loss: 1.9079\n",
            "Epoch 16/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9799 - loss: 0.0607 - val_accuracy: 0.7426 - val_loss: 1.9360\n",
            "Epoch 17/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0409 - val_accuracy: 0.7477 - val_loss: 2.0283\n",
            "Epoch 18/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0419 - val_accuracy: 0.7424 - val_loss: 2.1351\n",
            "Epoch 19/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0453 - val_accuracy: 0.7531 - val_loss: 1.9770\n",
            "Epoch 20/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0424 - val_accuracy: 0.7499 - val_loss: 2.1081\n",
            "Epoch 21/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0575 - val_accuracy: 0.7486 - val_loss: 2.1789\n",
            "Epoch 22/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0400 - val_accuracy: 0.7355 - val_loss: 2.1605\n",
            "Epoch 23/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0485 - val_accuracy: 0.7415 - val_loss: 2.2809\n",
            "Epoch 24/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0348 - val_accuracy: 0.7437 - val_loss: 2.3440\n",
            "Epoch 25/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.9858 - loss: 0.0474 - val_accuracy: 0.7511 - val_loss: 2.2965\n",
            "Epoch 26/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0489 - val_accuracy: 0.7427 - val_loss: 2.4478\n",
            "Epoch 27/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0340 - val_accuracy: 0.7478 - val_loss: 2.4074\n",
            "Epoch 28/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9879 - loss: 0.0363 - val_accuracy: 0.7373 - val_loss: 2.5506\n",
            "Epoch 29/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0541 - val_accuracy: 0.7472 - val_loss: 2.4458\n",
            "Epoch 30/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0333 - val_accuracy: 0.7446 - val_loss: 2.5130\n",
            "Epoch 31/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9852 - loss: 0.0499 - val_accuracy: 0.7357 - val_loss: 2.5141\n",
            "Epoch 32/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0356 - val_accuracy: 0.7391 - val_loss: 2.8290\n",
            "Epoch 33/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0356 - val_accuracy: 0.7393 - val_loss: 2.5788\n",
            "Epoch 34/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0473 - val_accuracy: 0.7349 - val_loss: 2.5071\n",
            "Epoch 35/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9892 - loss: 0.0373 - val_accuracy: 0.7445 - val_loss: 2.5817\n",
            "Epoch 36/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0258 - val_accuracy: 0.7323 - val_loss: 2.6465\n",
            "Epoch 37/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0499 - val_accuracy: 0.7402 - val_loss: 2.7475\n",
            "Epoch 38/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0381 - val_accuracy: 0.7376 - val_loss: 2.6700\n",
            "Epoch 39/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0434 - val_accuracy: 0.7434 - val_loss: 2.7092\n",
            "Epoch 40/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0483 - val_accuracy: 0.7403 - val_loss: 2.8245\n",
            "Epoch 41/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0419 - val_accuracy: 0.7472 - val_loss: 2.7978\n",
            "Epoch 42/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0369 - val_accuracy: 0.7443 - val_loss: 2.6984\n",
            "Epoch 43/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0393 - val_accuracy: 0.7438 - val_loss: 2.9060\n",
            "Epoch 44/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0477 - val_accuracy: 0.7498 - val_loss: 2.8414\n",
            "Epoch 45/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0170 - val_accuracy: 0.7282 - val_loss: 3.0856\n",
            "Epoch 46/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0373 - val_accuracy: 0.7327 - val_loss: 3.0317\n",
            "Epoch 47/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0406 - val_accuracy: 0.7366 - val_loss: 2.9988\n",
            "Epoch 48/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0281 - val_accuracy: 0.7382 - val_loss: 3.0099\n",
            "Epoch 49/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0410 - val_accuracy: 0.7411 - val_loss: 2.9784\n",
            "Epoch 50/50\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0455 - val_accuracy: 0.7383 - val_loss: 3.0684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Choose Adam (Adaptive Moment Estimation):\n",
        "Adam is one of the most popular optimizers for deep learning due to its adaptive learning rates and efficient handling of sparse gradients. It combines the benefits of both Momentum and RMSProp, which helps in faster convergence.\n",
        "\n",
        "## How Adam Works:\n",
        "\n",
        "Adam maintains a separate learning rate for each parameter, adjusting the learning rate dynamically for each one based on first-order moments (mean) and second-order moments (variance).\n",
        "It is well-suited for large datasets and problems with noisy gradients (like CIFAR-10)."
      ],
      "metadata": {
        "id": "xBZEPX-UgWL5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of optimizer and learning rate directly affects the speed and stability of the network's convergence. Optimizers like Adam adapt the learning rate during training, making them more efficient and robust in handling complex problems. A learning rate that's too high can cause the model to overshoot minima and fail to converge, while a rate that's too low results in slow learning. If the model isn't converging, reducing the learning rate can help by allowing the model to make more precise updates to the weights, leading to smoother convergence. Gradual learning rate decay is often used to fine-tune this process."
      ],
      "metadata": {
        "id": "jJCyQ0QzgrGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Optionally, you can plot the training and validation accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "S1gYF-SvgbAf",
        "outputId": "24371a57-ffc2-4bad-b95d-1e3fc2463611"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back Propagation\n",
        "Backpropagation updates the weights in each layer by calculating the gradient of the loss function with respect to each weight. It starts by computing the error at the output layer, then propagates this error backward through the network, layer by layer, using the chain rule of calculus to find how much each weight contributed to the error. This process generates the gradients (partial derivatives), which indicate the direction and magnitude of change needed for each weight to reduce the overall loss.\n",
        "\n",
        "## Learning Rate\n",
        "The learning rate controls how much the weights are adjusted based on these gradients. A larger learning rate makes bigger changes to the weights in each update, which can speed up learning but risks overshooting the optimal point. A smaller learning rate makes smaller, more precise updates, reducing the chance of overshooting but potentially slowing down convergence. The learning rate thus plays a crucial role in balancing speed and stability during the training process."
      ],
      "metadata": {
        "id": "Sb_YCcmJhtmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Get predictions for the test set\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Convert predictions and true labels from one-hot encoded to class labels\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate precision, recall, F1-score, and the confusion matrix\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAgKFKeFhsNL",
        "outputId": "e9cb4c9d-00ac-4282-90b3-cc0ef14c5bca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7454 - loss: 3.5249\n",
            "Test Accuracy: 0.748199999332428\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.80      0.79      1000\n",
            "           1       0.85      0.86      0.85      1000\n",
            "           2       0.66      0.65      0.65      1000\n",
            "           3       0.58      0.52      0.55      1000\n",
            "           4       0.68      0.73      0.71      1000\n",
            "           5       0.64      0.65      0.65      1000\n",
            "           6       0.81      0.80      0.80      1000\n",
            "           7       0.77      0.80      0.78      1000\n",
            "           8       0.84      0.87      0.85      1000\n",
            "           9       0.85      0.80      0.83      1000\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n",
            "Confusion Matrix:\n",
            "[[795  12  52  11  32  12   9  14  50  13]\n",
            " [ 11 859   8   7   4   9   9   5  19  69]\n",
            " [ 50   3 649  63  80  49  50  31  18   7]\n",
            " [ 29  10  67 520  75 156  60  59  13  11]\n",
            " [ 11   2  74  44 735  35  31  55   9   4]\n",
            " [ 17   2  49 142  49 651  21  43  16  10]\n",
            " [ 11   5  42  45  33  32 801  10  18   3]\n",
            " [ 10   1  23  34  59  53   7 796   9   8]\n",
            " [ 38  25   9  12   6  10   5   3 872  20]\n",
            " [ 30  91  12  14   6   9   2  15  17 804]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question:\n",
        "### How can you further improve model performance if the accuracy is low?\n",
        "To improve model performance if the accuracy is unsatisfactory, several strategies can be employed, including data augmentation techniques that introduce variability by applying transformations such as flips, rotations, and shifts to the training images, which helps the model generalize better. Implementing regularization methods like dropout can prevent overfitting by randomly disabling neurons during training, while increasing model complexity through deeper architectures or more neurons can enhance feature extraction capabilities. Additionally, hyperparameter tuning, such as adjusting the learning rate or batch size, along with training for more epochs, can lead to better convergence. Finally, leveraging transfer learning by fine-tuning pre-trained models on similar datasets can significantly enhance performance by utilizing learned features from larger datasets."
      ],
      "metadata": {
        "id": "EwEBnUvfizYg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimization strategies\n",
        "\n",
        "## Early Stopping:\n",
        " This technique monitors validation performance during training, halting the process when validation loss increases or accuracy plateaus, preventing overfitting and saving computational resources.\n",
        "\n",
        "## Learning Rate Scheduling:\n",
        " This approach adjusts the learning rate throughout training, starting high for larger weight updates and decreasing it later for finer adjustments. This facilitates smoother convergence and reduces the risk of overshooting the optimal solution.\n",
        "\n",
        "## Weight Initialization Techniques:\n",
        " Proper initialization, such as Xavier or He initialization, sets initial weights based on input and output units, maintaining healthy activation variance and preventing vanishing or exploding gradients. Effective weight initialization accelerates convergence and enhances learning.\n",
        "\n",
        "Implementing these strategies can lead to m"
      ],
      "metadata": {
        "id": "eabWtheU1Hsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges faced\n",
        "\n",
        "### Overfitting:\n",
        "Initially, the model showed signs of overfitting with high training accuracy but poor validation performance.\n",
        "Implemented early stopping and dropout layers to reduce overfitting.\n",
        "\n",
        "### Learning Rate Tuning:\n",
        "The initial learning rate resulted in unstable training.\n",
        "Solution: Adjusted the learning rate and employed learning rate scheduling to stabilize convergence.\n",
        "\n",
        "### Class Imbalance:\n",
        "Some classes had fewer samples than others.\n",
        "Solution: Used data augmentation techniques to create synthetic samples, thus balancing the dataset."
      ],
      "metadata": {
        "id": "1RpPlF1s4S8L"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mWTpJHoSjBa4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}